services:
  postgres:
    image: postgres:16-alpine
    container_name: cortex-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: cortex
      POSTGRES_PASSWORD: cortex_dev_password
      POSTGRES_DB: cortex
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cortex -d cortex"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: cortex-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: ["redis-server", "--appendonly", "yes", "--maxmemory", "256mb", "--maxmemory-policy", "allkeys-lru"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    restart: unless-stopped

  risk-engine:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cortex-risk-engine
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=info
      - CORTEX_API_KEYS=${CORTEX_API_KEYS:-}
      - CORTEX_ALLOWED_ORIGINS=${CORTEX_ALLOWED_ORIGINS:-http://localhost:8000}
      - CORTEX_RATE_LIMIT_READ=${CORTEX_RATE_LIMIT_READ:-60}
      - CORTEX_RATE_LIMIT_WRITE=${CORTEX_RATE_LIMIT_WRITE:-10}
      - REDIS_URL=redis://redis:6379/0
      - PERSISTENCE_REDIS_URL=redis://redis:6379/1
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 5s
      start_period: 10s
      retries: 3
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:v2.51.0
    container_name: cortex-prometheus
    profiles:
      - monitoring
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.retention.time=30d
    restart: unless-stopped

  grafana:
    image: grafana/grafana:11.0.0
    container_name: cortex-grafana
    profiles:
      - monitoring
    depends_on:
      - prometheus
    volumes:
      - ./monitoring/grafana/provisioning/dashboards/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml:ro
      - ./monitoring/grafana/cortex-dashboard.json:/etc/grafana/provisioning/dashboards/cortex-dashboard.json:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: cortex
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /etc/grafana/provisioning/dashboards/cortex-dashboard.json
    restart: unless-stopped

  # Ollama LLM backend for narrator (use: docker compose --profile narrator up)
  ollama:
    image: ollama/ollama:latest
    container_name: cortex-ollama
    profiles:
      - narrator
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped

  # Development mode with hot-reload (use: docker compose --profile dev up)
  risk-engine-dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cortex-risk-engine-dev
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      - ./api:/app/api
      - ./frontend:/app/frontend
      - ./cortex:/app/cortex
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=debug
      - CORTEX_API_KEYS=${CORTEX_API_KEYS:-}
      - CORTEX_ALLOWED_ORIGINS=${CORTEX_ALLOWED_ORIGINS:-*}
      - CORTEX_RATE_LIMIT_READ=${CORTEX_RATE_LIMIT_READ:-120}
      - CORTEX_RATE_LIMIT_WRITE=${CORTEX_RATE_LIMIT_WRITE:-30}
      - REDIS_URL=redis://redis:6379/0
      - PERSISTENCE_REDIS_URL=redis://redis:6379/1
    command: ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    profiles:
      - dev
    restart: unless-stopped

volumes:
  postgres_data:
  redis-data:
  prometheus_data:
  grafana_data:
  ollama_data:

